{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec865da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for cross-platform color support\n",
    "init(autoreset=True)\n",
    "\n",
    "# Color mapping by log level\n",
    "LOG_COLORS = {\n",
    "    logging.DEBUG: Fore.CYAN,\n",
    "    logging.INFO: Fore.GREEN,\n",
    "    logging.WARNING: Fore.YELLOW,\n",
    "    logging.ERROR: Fore.RED,\n",
    "    logging.CRITICAL: Fore.MAGENTA\n",
    "}\n",
    "\n",
    "class ColorFormatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        color = LOG_COLORS.get(record.levelno, \"\")\n",
    "        message = super().format(record)\n",
    "        return f\"{color}{message}{Style.RESET_ALL}\"\n",
    "\n",
    "def get_logger(name=\"AppLogger\", level=logging.INFO):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = ColorFormatter(\"[%(asctime)s] [%(levelname)s] %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = get_logger(\"DemoLogger\", logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "import pandas as pd\n",
    "\n",
    "session = get_active_session()\n",
    "\n",
    "table_name = \"ML_CREDIT.RAW_DATA.INSURANCE_CLAIMS\"\n",
    "claims = session.table(table_name)\n",
    "claims.show()\n",
    "\n",
    "\n",
    "logger.info(f\"Total de registros: {claims.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import avg, col,when, count, lit  # noqa: E402\n",
    "from snowflake.snowpark.functions import max as max_  # noqa: E402\n",
    "from snowflake.snowpark.functions import sum as sum_  # noqa: E402\n",
    "\n",
    "\n",
    "# 0. Fix AGE (likely missing value)\n",
    "claims = claims.with_column(\n",
    "    \"AGE\",\n",
    "    when((col(\"AGE\") <= 0) | (col(\"AGE\") > 120), lit(None)).otherwise(\n",
    "        col(\"AGE\").cast(\"int\")\n",
    "    ),\n",
    ")\n",
    "# 1. TEMPORAL FEATURES - Critical for fraud detection\n",
    "temporal_features = claims.select(\n",
    "    col(\"POLICYNUMBER\"),\n",
    "    col(\"MONTH\"),\n",
    "    col(\"WEEKOFMONTH\"),\n",
    "    # Convert categorical time ranges to numeric\n",
    "    when(col(\"DAYS_POLICY_CLAIM\") == \"more than 30\", 35)\n",
    "    .when(col(\"DAYS_POLICY_CLAIM\") == \"15 to 30\", 22)\n",
    "    .when(col(\"DAYS_POLICY_CLAIM\") == \"8 to 15\", 11)\n",
    "    .when(col(\"DAYS_POLICY_CLAIM\") == \"1 to 7\", 4)\n",
    "    .otherwise(0)\n",
    "    .alias(\"DAYS_TO_CLAIM_NUM\"),\n",
    "    when(col(\"DAYS_POLICY_ACCIDENT\") == \"more than 30\", 35)\n",
    "    .when(col(\"DAYS_POLICY_ACCIDENT\") == \"15 to 30\", 22)\n",
    "    .when(col(\"DAYS_POLICY_ACCIDENT\") == \"8 to 15\", 11)\n",
    "    .when(col(\"DAYS_POLICY_ACCIDENT\") == \"1 to 7\", 4)\n",
    "    .otherwise(0)\n",
    "    .alias(\"POLICY_AGE_AT_ACCIDENT\"),\n",
    "    # Suspicious if claim month differs from accident month\n",
    "    when(col(\"MONTH\") != col(\"MONTHCLAIMED\"), 1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"MONTH_MISMATCH\"),\n",
    "    # Suspicious if day of week differs\n",
    "    when(col(\"DAYOFWEEK\") != col(\"DAYOFWEEKCLAIMED\"), 1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"DAY_MISMATCH\"),\n",
    ")\n",
    "\n",
    "\n",
    "# 2. VEHICLE FEATURES\n",
    "vehicle_features = claims.select(\n",
    "    col(\"POLICYNUMBER\"),\n",
    "    col(\"MONTH\"),\n",
    "    col(\"WEEKOFMONTH\"),\n",
    "    # Vehicle age numeric\n",
    "    when(col(\"AGEOFVEHICLE\") == \"new\", 0)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"1 year\", 1)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"2 years\", 2)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"3 years\", 3)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"4 years\", 4)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"5 years\", 5)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"6 years\", 6)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"7 years\", 7)\n",
    "    .when(col(\"AGEOFVEHICLE\") == \"more than 7\", 9)\n",
    "    .otherwise(None)\n",
    "    .alias(\"VEHICLE_AGE_NUM\"),\n",
    "    # Vehicle price midpoint\n",
    "    when(col(\"VEHICLEPRICE\") == \"less than 20000\", 15000)\n",
    "    .when(col(\"VEHICLEPRICE\") == \"20000 to 29000\", 24500)\n",
    "    .when(col(\"VEHICLEPRICE\") == \"30000 to 39000\", 34500)\n",
    "    .when(col(\"VEHICLEPRICE\") == \"40000 to 59000\", 49500)\n",
    "    .when(col(\"VEHICLEPRICE\") == \"60000 to 69000\", 64500)\n",
    "    .when(col(\"VEHICLEPRICE\") == \"more than 69000\", 80000)\n",
    "    .otherwise(None)\n",
    "    .alias(\"VEHICLE_PRICE_NUM\"),\n",
    "    # Risk factors based on insurance industry data\n",
    "    when(col(\"VEHICLECATEGORY\") == \"Sport\", 3)\n",
    "    .when(col(\"VEHICLECATEGORY\") == \"Utility\", 2)\n",
    "    .when(col(\"VEHICLECATEGORY\") == \"Sedan\", 1)\n",
    "    .otherwise(1)\n",
    "    .alias(\"VEHICLE_RISK\"),\n",
    ")\n",
    "\n",
    "# 3. DEMOGRAPHIC FEATURES\n",
    "demographic_features = claims.select(\n",
    "    col(\"POLICYNUMBER\"),\n",
    "    col(\"MONTH\"),\n",
    "    col(\"WEEKOFMONTH\"),\n",
    "    # Age risk (young and elderly are higher risk)\n",
    "    when(col(\"AGE\") < 25, 3)\n",
    "    .when(col(\"AGE\").between(25, 35), 2)\n",
    "    .when(col(\"AGE\").between(36, 60), 1)\n",
    "    .when(col(\"AGE\") > 60, 2)\n",
    "    .otherwise(2)\n",
    "    .alias(\"AGE_RISK\"),\n",
    "    # Binary encodings\n",
    "    when(col(\"SEX\") == \"Male\", 1).otherwise(0).alias(\"IS_MALE\"),\n",
    "    when(col(\"MARITALSTATUS\") == \"Single\", 1).otherwise(0).alias(\"IS_SINGLE\"),\n",
    "    # Driver rating (already numeric)\n",
    "    col(\"DRIVERRATING\"),\n",
    "    # Policyholder age midpoint\n",
    "    when(col(\"AGEOFPOLICYHOLDER\") == \"16 to 17\", 16.5)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"18 to 20\", 19)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"21 to 25\", 23)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"26 to 30\", 28)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"31 to 35\", 33)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"36 to 40\", 38)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"41 to 50\", 45.5)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"51 to 65\", 58)\n",
    "    .when(col(\"AGEOFPOLICYHOLDER\") == \"over 65\", 72)\n",
    "    .otherwise(None)\n",
    "    .alias(\"POLICYHOLDER_AGE\"),\n",
    ")\n",
    "\n",
    " # 4. CLAIM RISK FACTORS - Most important for fraud detection\n",
    "\n",
    "claim_risk_features = claims.select(\n",
    "    col(\"POLICYNUMBER\"),\n",
    "    col(\"MONTH\"),\n",
    "    col(\"WEEKOFMONTH\"),\n",
    "    # Fault\n",
    "    when(col(\"FAULT\") == \"Policy Holder\", 1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"POLICYHOLDER_FAULT\"),\n",
    "    # Deductible\n",
    "    col(\"DEDUCTIBLE\"),\n",
    "    # Past claims (strong fraud indicator)\n",
    "    when(col(\"PASTNUMBEROFCLAIMS\") == \"none\", 0)\n",
    "    .when(col(\"PASTNUMBEROFCLAIMS\") == \"1\", 1)\n",
    "    .when(col(\"PASTNUMBEROFCLAIMS\") == \"2 to 4\", 3)\n",
    "    .when(col(\"PASTNUMBEROFCLAIMS\") == \"more than 4\", 6)\n",
    "    .otherwise(0)\n",
    "    .alias(\"PAST_CLAIMS\"),\n",
    "    # Documentation flags (strong fraud indicators)\n",
    "    when(col(\"POLICEREPORTFILED\") == \"No\", 1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"NO_POLICE_REPORT\"),\n",
    "    when(col(\"WITNESSPRESENT\") == \"No\", 1).otherwise(0).alias(\"NO_WITNESS\"),\n",
    "    # Claim supplements\n",
    "    when(col(\"NUMBEROFSUPPLIMENTS\") == \"none\", 0)\n",
    "    .when(col(\"NUMBEROFSUPPLIMENTS\") == \"1 to 2\", 1.5)\n",
    "    .when(col(\"NUMBEROFSUPPLIMENTS\") == \"3 to 5\", 4)\n",
    "    .when(col(\"NUMBEROFSUPPLIMENTS\") == \"more than 5\", 7)\n",
    "    .otherwise(0)\n",
    "    .alias(\"SUPPLEMENTS\"),\n",
    "    # Address change (fraud red flag)\n",
    "    when(col(\"ADDRESSCHANGE_CLAIM\") == \"1 year\", 1)\n",
    "    .when(col(\"ADDRESSCHANGE_CLAIM\") == \"2 to 3 years\", 0.5)\n",
    "    .when(col(\"ADDRESSCHANGE_CLAIM\") == \"4 to 8 years\", 0.2)\n",
    "    .when(col(\"ADDRESSCHANGE_CLAIM\") == \"no change\", 0)\n",
    "    .otherwise(0)\n",
    "    .alias(\"ADDRESS_CHANGE\"),\n",
    "    # Location and agent\n",
    "    when(col(\"ACCIDENTAREA\") == \"Urban\", 1).otherwise(0).alias(\"URBAN_ACCIDENT\"),\n",
    "    when(col(\"AGENTTYPE\") == \"External\", 1).otherwise(0).alias(\"EXTERNAL_AGENT\"),\n",
    "    # Target\n",
    "    col(\"FRAUDFOUND_P\").alias(\"IS_FRAUD\"),\n",
    ")\n",
    "\n",
    "# 5. POLICY AGGREGATIONS - Historical behavior\n",
    "\n",
    "policy_agg = claims.group_by(\"POLICYNUMBER\").agg(\n",
    "    count(col(\"POLICYNUMBER\")).alias(\"TOTAL_CLAIMS_POLICY\"),\n",
    "    sum_(col(\"FRAUDFOUND_P\")).alias(\"FRAUD_COUNT_POLICY\"),\n",
    "    avg(col(\"DEDUCTIBLE\")).alias(\"AVG_DEDUCTIBLE_POLICY\"),\n",
    "    avg(col(\"DRIVERRATING\")).alias(\"AVG_RATING_POLICY\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c605a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# JOIN ALL FEATURES\n",
    "# ======================================================================\n",
    "logger.info(\"Joining all feature sets\")\n",
    "\n",
    "# Use USING clause to avoid duplicate columns\n",
    "all_features = claim_risk_features.join(\n",
    "    temporal_features, [\"POLICYNUMBER\", \"MONTH\", \"WEEKOFMONTH\"], \"left\"\n",
    ")\n",
    "\n",
    "all_features = all_features.join(\n",
    "    vehicle_features, [\"POLICYNUMBER\", \"MONTH\", \"WEEKOFMONTH\"], \"left\"\n",
    ")\n",
    "\n",
    "all_features = all_features.join(\n",
    "    demographic_features, [\"POLICYNUMBER\", \"MONTH\", \"WEEKOFMONTH\"], \"left\"\n",
    ")\n",
    "\n",
    "all_features = all_features.join(policy_agg, \"POLICYNUMBER\", \"left\")\n",
    "\n",
    "# ======================================================================\n",
    "# INTERACTION FEATURES - Capture complex fraud patterns\n",
    "# ======================================================================\n",
    "logger.info(\"Creating interaction features\")\n",
    "\n",
    "final_features = all_features.select(\n",
    "    \"*\",\n",
    "    # Quick claim + no police report = very suspicious\n",
    "    (col(\"DAYS_TO_CLAIM_NUM\") * col(\"NO_POLICE_REPORT\")).alias(\"QUICK_NO_POLICE\"),\n",
    "    # Vehicle depreciation vs price\n",
    "    (col(\"VEHICLE_AGE_NUM\") * col(\"VEHICLE_PRICE_NUM\") / 10000).alias(\n",
    "        \"VEHICLE_DEPRECIATION\"\n",
    "    ),\n",
    "    # External agent in urban area\n",
    "    (col(\"EXTERNAL_AGENT\") * col(\"URBAN_ACCIDENT\")).alias(\"EXTERNAL_URBAN\"),\n",
    "    # Address change with past claims\n",
    "    (col(\"ADDRESS_CHANGE\") * col(\"PAST_CLAIMS\")).alias(\"ADDRESS_PAST_CLAIMS\"),\n",
    "    # Young driver with sport vehicle\n",
    "    (when(col(\"AGE_RISK\") == 3, 1).otherwise(0) * col(\"VEHICLE_RISK\")).alias(\n",
    "        \"YOUNG_SPORT\"\n",
    "    ),\n",
    "    # New policy with claim\n",
    "    (\n",
    "        when(col(\"POLICY_AGE_AT_ACCIDENT\") < 15, 1).otherwise(0) * col(\"DEDUCTIBLE\")\n",
    "    ).alias(\"NEW_POLICY_CLAIM\"),\n",
    "    # No documentation (police + witness)\n",
    "    (col(\"NO_POLICE_REPORT\") * col(\"NO_WITNESS\")).alias(\"NO_DOCUMENTATION\"),\n",
    ")\n",
    "\n",
    "# ======================================================================\n",
    "# CLASS IMBALANCE HANDLING\n",
    "# ======================================================================\n",
    "logger.info(\"Calculating class weights for imbalanced data\")\n",
    "\n",
    "fraud_stats = session.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        SUM(CASE WHEN FRAUDFOUND_P = 1 THEN 1 ELSE 0 END) AS FRAUD_COUNT,\n",
    "        COUNT(*) AS TOTAL_COUNT\n",
    "    FROM ML_CREDIT.RAW_DATA.INSURANCE_CLAIMS\n",
    "\"\"\"\n",
    ").collect()[0]\n",
    "\n",
    "fraud_count = fraud_stats[\"FRAUD_COUNT\"]\n",
    "total_count = fraud_stats[\"TOTAL_COUNT\"]\n",
    "fraud_ratio = fraud_count / total_count\n",
    "\n",
    "logger.info(f\"Fraud ratio: {fraud_ratio:.4f} ({fraud_count}/{total_count})\")\n",
    "\n",
    "# Add sample weights (inverse of class frequency)\n",
    "weighted_features = final_features.select(\n",
    "    \"*\",\n",
    "    when(col(\"IS_FRAUD\") == 1, (1 - fraud_ratio) / fraud_ratio)\n",
    "    .otherwise(1.0)\n",
    "    .alias(\"SAMPLE_WEIGHT\"),\n",
    ")\n",
    "\n",
    "# ======================================================================\n",
    "# REGISTER FEATURE VIEWS\n",
    "# ======================================================================\n",
    "logger.info(\"Registering feature views in Feature Store\")\n",
    "weighted_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col, when, mean, median\n",
    "\n",
    "logger.info(\"Imputing null values in numeric features\")\n",
    "\n",
    "# Impute nulls in DEDUCTIBLE with median\n",
    "median_deductible = weighted_features.select(median(col(\"DEDUCTIBLE\"))).collect()[0][0]\n",
    "weighted_features = weighted_features.with_column(\n",
    "    \"DEDUCTIBLE\",\n",
    "    when(col(\"DEDUCTIBLE\").is_null(), median_deductible).otherwise(col(\"DEDUCTIBLE\"))\n",
    ")\n",
    "\n",
    "# Impute nulls in VEHICLE_PRICE_NUM with mean\n",
    "mean_vehicle_price = weighted_features.select(mean(col(\"VEHICLE_PRICE_NUM\"))).collect()[0][0]\n",
    "weighted_features = weighted_features.with_column(\n",
    "    \"VEHICLE_PRICE_NUM\",\n",
    "    when(col(\"VEHICLE_PRICE_NUM\").is_null(), mean_vehicle_price).otherwise(col(\"VEHICLE_PRICE_NUM\"))\n",
    ")\n",
    "\n",
    "logger.info(\"Imputation completed\")\n",
    "weighted_features.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# MODEL TRAINING - LOGISTIC REGRESSION (Luis Vejarano)\n",
    "# ======================================================================\n",
    "# Assuming weighted_features is your Snowpark DataFrame from previous cells\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Convert to pandas for training\n",
    "training_data = weighted_features.to_pandas()\n",
    "\n",
    "# Prepare features and target\n",
    "exclude_cols = [\"POLICYNUMBER\", \"MONTH\", \"WEEKOFMONTH\", \"SAMPLE_WEIGHT\"]\n",
    "feature_cols = [c for c in training_data.columns if c not in exclude_cols and c != \"IS_FRAUD\"]\n",
    "\n",
    "# For now I am not going to do the stuff related to train/test/validation + cross validation ... (but you can guys add it)\n",
    "X = training_data[feature_cols]\n",
    "y = training_data[\"IS_FRAUD\"]\n",
    "sample_weight = training_data[\"SAMPLE_WEIGHT\"] if \"SAMPLE_WEIGHT\" in training_data.columns else None\n",
    "\n",
    "# Calculate class imbalance ratio for class_weight\n",
    "fraud_count = y.sum()\n",
    "non_fraud_count = len(y) - fraud_count\n",
    "class_weight_ratio = non_fraud_count / fraud_count\n",
    "logger.info(f\"Calculated class_weight ratio: {class_weight_ratio:.2f}\")\n",
    "\n",
    "# Feature scaling (critical for Logistic Regression)\n",
    "logger.info(\"Scaling features with StandardScaler...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Configure Logistic Regression with class imbalance handling\n",
    "logger.info(\"Starting model training with Logistic Regression...\")\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,                                    # Maximum iterations for convergence\n",
    "    class_weight={0: 1.0, 1: class_weight_ratio},    # Class imbalance handling\n",
    "    random_state=42,                                  # Reproducibility\n",
    "    solver='lbfgs',                                   # Optimization algorithm\n",
    "    C=1.0,                                           # Regularization strength (inverse)\n",
    "    verbose=0,                                       # No verbose output\n",
    "    n_jobs=1                                        # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_scaled, y, sample_weight=sample_weight)\n",
    "\n",
    "# Comprehensive evaluation metrics\n",
    "y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "# Calculate multiple metrics\n",
    "auc = roc_auc_score(y, y_pred_proba)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "# Log all metrics\n",
    "logger.info(f\"Training AUC: {auc:.4f}\")\n",
    "logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "logger.info(f\"Precision: {precision:.4f}\")\n",
    "logger.info(f\"Recall: {recall:.4f}\")\n",
    "logger.info(f\"F1-Score: {f1:.4f}\")\n",
    "logger.info(\"Model trained successfully with Logistic Regression and class imbalance handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e96bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# SAVE METRICS TO TABLE - Luis Vejarano\n",
    "# ======================================================================\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "metrics_table = \"ML_CREDIT.ANALYTICS.MODEL_METRICS\"\n",
    "\n",
    "# Create metrics table if it doesn't exist\n",
    "session.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {metrics_table} (\n",
    "    MODEL_NAME STRING,\n",
    "    MODEL_VERSION STRING,\n",
    "    FRAMEWORK STRING,\n",
    "    TRAINING_DATE TIMESTAMP_NTZ,\n",
    "    AUC FLOAT,\n",
    "    ACCURACY FLOAT,\n",
    "    PRECISION FLOAT,\n",
    "    RECALL FLOAT,\n",
    "    F1_SCORE FLOAT,\n",
    "    CREATED_BY STRING\n",
    ")\n",
    "\"\"\").collect()\n",
    "\n",
    "# Insert metrics\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO {metrics_table}\n",
    "VALUES (?, ?, ?, CURRENT_TIMESTAMP(), ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "params = [\n",
    "    \"vehicle_insurance_fraud_detector\",  # MODEL_NAME\n",
    "    \"1.0.2_logistic\",                    # MODEL_VERSION\n",
    "    \"logistic_regression\",               # FRAMEWORK\n",
    "    float(auc),                          # AUC\n",
    "    float(accuracy),                     # ACCURACY\n",
    "    float(precision),                    # PRECISION\n",
    "    float(recall),                       # RECALL\n",
    "    float(f1),                           # F1_SCORE\n",
    "    \"Luis Vejarano\"                      # CREATED_BY\n",
    "]\n",
    "\n",
    "session.sql(insert_sql, params=params).collect()\n",
    "\n",
    "logger.info(\"Metrics saved to ML_CREDIT.ANALYTICS.MODEL_METRICS\")\n",
    "\n",
    "# Show saved metrics\n",
    "session.sql(f\"SELECT * FROM {metrics_table} ORDER BY TRAINING_DATE DESC LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d324d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# REGISTER MODEL - Save model artifact to Snowflake Stage (Luis Bejarano)\n",
    "# ======================================================================\n",
    "# Prereqs: model and scaler are already trained in previous cells\n",
    "\n",
    "import os, json, tempfile, joblib\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "session = get_active_session()\n",
    "database = \"ML_CREDIT\"\n",
    "stage = f\"{database}.MODELS.ML_MODELS_STAGE\"\n",
    "artifact_filename = \"fraud_detector_logistic_v1_0_2.joblib\"\n",
    "\n",
    "# 1) Save model and scaler to a local file\n",
    "logger.info(\"Saving model and scaler to local file...\")\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    local_path = os.path.join(tmpdir, artifact_filename)\n",
    "    # Save both model and scaler together (needed for predictions)\n",
    "    joblib.dump({'model': model, 'scaler': scaler}, local_path)\n",
    "    \n",
    "    # 2) Upload to Snowflake Stage\n",
    "    logger.info(f\"Uploading model to Snowflake Stage: {stage}\")\n",
    "    session.file.put(\n",
    "        local_path,\n",
    "        f\"@{stage}\",\n",
    "        overwrite=True,\n",
    "        auto_compress=False\n",
    "    )\n",
    "\n",
    "artifact_uri = f\"@{stage}/{artifact_filename}\"\n",
    "\n",
    "# 3) Create registry table for Logistic Regression models\n",
    "registry_table = f\"{database}.MODELS.MODEL_REGISTRY_LOGISTIC\"\n",
    "session.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {registry_table} (\n",
    "  MODEL_NAME STRING,\n",
    "  MODEL_VER  STRING,\n",
    "  STAGE_NAME STRING,\n",
    "  ARTIFACT_URI STRING,\n",
    "  FRAMEWORK STRING,\n",
    "  METRICS VARIANT,\n",
    "  CREATED_AT TIMESTAMP_NTZ,\n",
    "  CREATED_BY STRING\n",
    ")\n",
    "\"\"\").collect()\n",
    "\n",
    "# 4) Prepare metrics to save with model\n",
    "metrics_json = {\n",
    "    \"auc\": float(auc),\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"precision\": float(precision),\n",
    "    \"recall\": float(recall),\n",
    "    \"f1\": float(f1)\n",
    "}\n",
    "\n",
    "# 5) Insert model registry record\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO {registry_table}\n",
    "  (MODEL_NAME, MODEL_VER, STAGE_NAME, ARTIFACT_URI, FRAMEWORK, METRICS, CREATED_AT, CREATED_BY)\n",
    "SELECT ?, ?, ?, ?, ?, PARSE_JSON(?), CURRENT_TIMESTAMP(), ?\n",
    "\"\"\"\n",
    "\n",
    "params = [\n",
    "    \"vehicle_insurance_fraud_detector\",  # MODEL_NAME\n",
    "    \"1.0.2_logistic\",                    # MODEL_VER\n",
    "    \"DEV\",                               # STAGE_NAME\n",
    "    artifact_uri,                        # ARTIFACT_URI\n",
    "    \"logistic_regression\",               # FRAMEWORK\n",
    "    json.dumps(metrics_json),            # METRICS\n",
    "    \"Luis Bejarano\"                      # CREATED_BY\n",
    "]\n",
    "\n",
    "session.sql(insert_sql, params=params).collect()\n",
    "\n",
    "logger.info(f\"✓ Model saved to: {artifact_uri}\")\n",
    "logger.info(f\"✓ Model registered in: {registry_table}\")\n",
    "\n",
    "# 6) Verify registration\n",
    "logger.info(\"Latest registered model:\")\n",
    "session.sql(f\"SELECT * FROM {registry_table} ORDER BY CREATED_AT DESC LIMIT 1\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
